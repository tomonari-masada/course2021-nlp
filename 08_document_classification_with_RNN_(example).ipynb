{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtbbXGNJnJQB"
   },
   "source": [
    "# RNNを使った文書分類（解答例）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "id": "2VicF1RrhJfa"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchtext import datasets\n",
    "\n",
    "SEED = 123\n",
    "\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OeCGHBNAojNh"
   },
   "source": [
    "### 訓練データから語彙集合を作成\n",
    "* データの読み込みや前処理は`torchtext`の旧バージョン（0.9より前）とかなり変わっているので注意。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Wqzi13k9LxZk",
    "outputId": "96315e52-ab00-4e01-ce89-aa28a4ffa7ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.10.1'"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchtext\n",
    "torchtext.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Hm83eK1dzJk"
   },
   "source": [
    "* データセットの訓練データ部分をもとに語彙セットを作成する。\n",
    " * 語彙セットを作成するとき、テストデータ部分を使わないように。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jug86Tt9hMMD",
    "outputId": "459338a4-2cfb-4193-888a-36ab159634b8"
   },
   "outputs": [],
   "source": [
    "from torchtext.datasets import IMDB\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "#tokenizer = get_tokenizer('spacy') # やや時間がかかる。\n",
    "\n",
    "# IMDbデータの訓練データ部分のイテレータを取得\n",
    "train_iter = IMDB(split='train', root='/home/masada/.data/')\n",
    "\n",
    "# 各文書をtokenizeするヘルパ関数\n",
    "def yield_tokens(data_iter):\n",
    "  for _, text in data_iter:\n",
    "    yield tokenizer(text)\n",
    "\n",
    "# 最小の出現頻度をmin_freqで指定して語彙サイズを調整する\n",
    "vocab = build_vocab_from_iterator(yield_tokens(train_iter),\n",
    "                                  specials=[\"<unk>\", \"<pad>\"],\n",
    "                                  min_freq=10)\n",
    "\n",
    "# OoVトークンには\"<unk>\"のインデックスを返すことにする\n",
    "vocab.set_default_index(vocab[\"<unk>\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gechUbtcgFld",
    "outputId": "eb1fd822-1df7-466c-ac05-623a629cee4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20437\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnnKq-ZDePk3",
    "outputId": "b59deb58-d0ff-44ad-f70d-62fab7825c61"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[132, 10, 41, 465]"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['here', 'is', 'an', 'example'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6ll_hOzMoA7",
    "outputId": "09931756-a68c-4659-e85f-076aede393e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab(['<unk>', '<pad>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDjU2ykppyi2"
   },
   "source": [
    "### IMDBデータを分割してデータセットを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "id": "qZKysnlAhjGS"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "\n",
    "train_iter, test_iter = IMDB(root='/home/masada/.data/')\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)\n",
    "\n",
    "# 訓練データ部分から検証データを切り出す\n",
    "num_train = int(len(train_dataset) * 0.9)\n",
    "split_train_, split_valid_ = random_split(train_dataset, [num_train, len(train_dataset) - num_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWj4V2YNlPvR"
   },
   "source": [
    "### RNNへの入力として使えるミニバッチを作る関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "id": "Vznl9uJZkpZn"
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_batch(batch):\n",
    "  labels = {'neg':0, 'pos':1}\n",
    "  label_list, text_list = [], []\n",
    "  for _label, _text in batch:\n",
    "    label_list.append(labels[_label])\n",
    "    processed_text = torch.tensor(vocab(tokenizer(_text)), dtype=torch.int64)\n",
    "    text_list.append(processed_text)\n",
    "  label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "  text_list = pad_sequence(text_list, batch_first=False, padding_value=PAD_IDX)\n",
    "  return label_list.to(device), text_list.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "id": "lgRH591zmEE4"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "train_dataloader = DataLoader(split_train_, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                              collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "id": "FJ90Cx3er_t-"
   },
   "outputs": [],
   "source": [
    "valid_dataloader = DataLoader(split_valid_, batch_size=BATCH_SIZE, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57xqsnpTnE_c"
   },
   "source": [
    "## モデルの定義\n",
    "* LSTMを使う（GRUに変えても良い）\n",
    " * http://colah.github.io/posts/2015-08-Understanding-LSTMs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "id": "r1wcVHcmg9KI"
   },
   "outputs": [],
   "source": [
    "class RNNTextSentiment(nn.Module):\n",
    "  def __init__(self, emb_dim, hid_dim,\n",
    "               num_class, vocab_size, padding_idx,\n",
    "               num_layers=1, bidirectional=False, p=0.5):\n",
    "    super().__init__()\n",
    "\n",
    "    self.input_dim = vocab_size\n",
    "    self.emb_dim = emb_dim\n",
    "    self.hid_dim = hid_dim\n",
    "    self.dropout = p\n",
    "\n",
    "    self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=padding_idx)\n",
    "    self.rnn = nn.LSTM(emb_dim, hid_dim, num_layers=num_layers)\n",
    "    self.fc1 = nn.Linear(hid_dim * (1 + num_layers), hid_dim)\n",
    "    self.fc2 = nn.Linear(hid_dim, num_class)\n",
    "    self.af = nn.ReLU()\n",
    "    self.dropout = nn.Dropout(p=p)\n",
    "\n",
    "  def forward(self, src):\n",
    "    # srcの形は[単語列長, バッチサイズ]\n",
    "\n",
    "    embedded = self.dropout(self.embedding(src))\n",
    "    # embeddedの形は[単語列長, バッチサイズ, 埋め込み次元数]\n",
    "\n",
    "    outputs, (hidden, _) = self.rnn(embedded)\n",
    "    # outputsの形は[単語列長, バッチサイズ, 隠れ状態の次元数]\n",
    "    # hiddenの形は[1, バッチサイズ, 隠れ状態の次元数]\n",
    "\n",
    "    mean_outputs = outputs.mean(0)\n",
    "    hidden = hidden.transpose(0, 1)\n",
    "    hidden = hidden.reshape(hidden.shape[0], -1)\n",
    "    # mean_outputsの形は[バッチサイズ, 隠れ状態の次元数]\n",
    "    # hiddenの形は[バッチサイズ, 隠れ状態の次元数]\n",
    "    output = self.fc2(self.af(self.fc1(torch.cat((mean_outputs, hidden), dim=1))))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "id": "gg1tuw6y4-Or"
   },
   "outputs": [],
   "source": [
    "def train(model, loader, optimizer, criterion, clip):\n",
    "  model.train()\n",
    "\n",
    "  epoch_loss = 0.\n",
    "  epoch_acc = 0.\n",
    "  for label, text in loader:\n",
    "    output = model(text)\n",
    "    loss = criterion(output, label)\n",
    "    loss.backward()\n",
    "\n",
    "    nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    epoch_loss += loss.item()\n",
    "    epoch_acc += (output.argmax(1) == label).sum().item()\n",
    "\n",
    "  return epoch_loss / len(loader), epoch_acc / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "id": "2qmfP-By5fOm"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion):\n",
    "  model.eval()\n",
    "\n",
    "  epoch_loss = 0.\n",
    "  epoch_acc = 0.\n",
    "  with torch.no_grad():\n",
    "    for label, text in loader:\n",
    "      output = model(text)\n",
    "      loss = criterion(output, label)\n",
    "      epoch_loss += loss.item()\n",
    "      epoch_acc += (output.argmax(1) == label).sum().item()\n",
    "\n",
    "  return epoch_loss / len(loader), epoch_acc / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "id": "xcPnwzJz5rnV"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "  elapsed_time = end_time - start_time\n",
    "  elapsed_mins = int(elapsed_time // 60)\n",
    "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "  return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "id": "W_3KWMr4hwxl"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(vocab)\n",
    "NUM_CLASS = 2\n",
    "EMBED_DIM = 128\n",
    "HIDDEN_DIM = 128\n",
    "NUM_LAYERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "id": "GuW6ghef34R4"
   },
   "outputs": [],
   "source": [
    "model = RNNTextSentiment(EMBED_DIM, HIDDEN_DIM, NUM_CLASS, INPUT_DIM,\n",
    "                         num_layers=NUM_LAYERS, bidirectional=True,\n",
    "                         padding_idx=PAD_IDX, p=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h06O037X4vRV",
    "outputId": "8b3a558d-90f0-4578-ca74-a85cdf26d59e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,929,666 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "id": "QaEbLC9T4pxb"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0003)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "id": "P5w-1q7u47Ax"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "ioV2XRKG5tf-",
    "outputId": "0e43f5cc-a5fc-438c-baf7-6c7fbbe3e944"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.6921 (train)\t|\tAcc 50.8% (train)\n",
      "\tLoss 0.6761 (valid)\t|\tAcc 57.3% (valid)\n",
      "Epoch 2 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.6486 (train)\t|\tAcc 62.7% (train)\n",
      "\tLoss 0.6009 (valid)\t|\tAcc 69.0% (valid)\n",
      "Epoch 3 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.5914 (train)\t|\tAcc 68.8% (train)\n",
      "\tLoss 0.5861 (valid)\t|\tAcc 70.1% (valid)\n",
      "Epoch 4 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.5148 (train)\t|\tAcc 75.2% (train)\n",
      "\tLoss 0.5115 (valid)\t|\tAcc 77.6% (valid)\n",
      "Epoch 5 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.4635 (train)\t|\tAcc 78.7% (train)\n",
      "\tLoss 0.5419 (valid)\t|\tAcc 76.4% (valid)\n",
      "Epoch 6 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.4336 (train)\t|\tAcc 80.0% (train)\n",
      "\tLoss 0.4023 (valid)\t|\tAcc 82.4% (valid)\n",
      "Epoch 7 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.4018 (train)\t|\tAcc 82.4% (train)\n",
      "\tLoss 0.3853 (valid)\t|\tAcc 84.4% (valid)\n",
      "Epoch 8 | time in 0 minutes, 15 seconds\n",
      "\tLoss 0.3709 (train)\t|\tAcc 83.8% (train)\n",
      "\tLoss 0.3461 (valid)\t|\tAcc 86.6% (valid)\n",
      "Epoch 9 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.3506 (train)\t|\tAcc 84.7% (train)\n",
      "\tLoss 0.3344 (valid)\t|\tAcc 86.8% (valid)\n",
      "Epoch 10 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.3305 (train)\t|\tAcc 86.0% (train)\n",
      "\tLoss 0.3311 (valid)\t|\tAcc 87.2% (valid)\n",
      "Epoch 11 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.3162 (train)\t|\tAcc 86.5% (train)\n",
      "\tLoss 0.3366 (valid)\t|\tAcc 87.0% (valid)\n",
      "Epoch 12 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.3061 (train)\t|\tAcc 87.2% (train)\n",
      "\tLoss 0.2956 (valid)\t|\tAcc 89.3% (valid)\n",
      "Epoch 13 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2845 (train)\t|\tAcc 88.0% (train)\n",
      "\tLoss 0.3257 (valid)\t|\tAcc 87.6% (valid)\n",
      "Epoch 14 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2766 (train)\t|\tAcc 88.4% (train)\n",
      "\tLoss 0.2910 (valid)\t|\tAcc 89.4% (valid)\n",
      "Epoch 15 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2700 (train)\t|\tAcc 88.8% (train)\n",
      "\tLoss 0.3120 (valid)\t|\tAcc 87.9% (valid)\n",
      "Epoch 16 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2669 (train)\t|\tAcc 88.9% (train)\n",
      "\tLoss 0.2878 (valid)\t|\tAcc 89.6% (valid)\n",
      "Epoch 17 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2515 (train)\t|\tAcc 89.5% (train)\n",
      "\tLoss 0.2772 (valid)\t|\tAcc 90.4% (valid)\n",
      "Epoch 18 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2509 (train)\t|\tAcc 89.5% (train)\n",
      "\tLoss 0.3036 (valid)\t|\tAcc 90.2% (valid)\n",
      "Epoch 19 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2394 (train)\t|\tAcc 90.2% (train)\n",
      "\tLoss 0.2682 (valid)\t|\tAcc 90.8% (valid)\n",
      "Epoch 20 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2319 (train)\t|\tAcc 90.6% (train)\n",
      "\tLoss 0.3081 (valid)\t|\tAcc 90.4% (valid)\n",
      "Epoch 21 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2202 (train)\t|\tAcc 91.2% (train)\n",
      "\tLoss 0.2937 (valid)\t|\tAcc 90.4% (valid)\n",
      "Epoch 22 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2108 (train)\t|\tAcc 91.5% (train)\n",
      "\tLoss 0.2830 (valid)\t|\tAcc 90.8% (valid)\n",
      "Epoch 23 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2081 (train)\t|\tAcc 91.7% (train)\n",
      "\tLoss 0.2826 (valid)\t|\tAcc 90.3% (valid)\n",
      "Epoch 24 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2101 (train)\t|\tAcc 91.5% (train)\n",
      "\tLoss 0.2729 (valid)\t|\tAcc 90.8% (valid)\n",
      "Epoch 25 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2110 (train)\t|\tAcc 91.5% (train)\n",
      "\tLoss 0.2862 (valid)\t|\tAcc 90.8% (valid)\n",
      "Epoch 26 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2064 (train)\t|\tAcc 91.5% (train)\n",
      "\tLoss 0.2809 (valid)\t|\tAcc 90.8% (valid)\n",
      "Epoch 27 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2088 (train)\t|\tAcc 91.5% (train)\n",
      "\tLoss 0.2806 (valid)\t|\tAcc 90.8% (valid)\n",
      "Epoch 28 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2048 (train)\t|\tAcc 91.9% (train)\n",
      "\tLoss 0.2822 (valid)\t|\tAcc 90.8% (valid)\n",
      "Epoch 29 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2048 (train)\t|\tAcc 91.8% (train)\n",
      "\tLoss 0.2845 (valid)\t|\tAcc 90.8% (valid)\n",
      "Epoch 30 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2045 (train)\t|\tAcc 91.9% (train)\n",
      "\tLoss 0.2910 (valid)\t|\tAcc 90.5% (valid)\n",
      "Epoch 31 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2036 (train)\t|\tAcc 91.8% (train)\n",
      "\tLoss 0.2725 (valid)\t|\tAcc 90.9% (valid)\n",
      "Epoch 32 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2004 (train)\t|\tAcc 92.0% (train)\n",
      "\tLoss 0.2894 (valid)\t|\tAcc 90.5% (valid)\n",
      "Epoch 33 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.1984 (train)\t|\tAcc 92.1% (train)\n",
      "\tLoss 0.2715 (valid)\t|\tAcc 91.0% (valid)\n",
      "Epoch 34 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2021 (train)\t|\tAcc 91.7% (train)\n",
      "\tLoss 0.2768 (valid)\t|\tAcc 91.2% (valid)\n",
      "Epoch 35 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2001 (train)\t|\tAcc 92.0% (train)\n",
      "\tLoss 0.2733 (valid)\t|\tAcc 90.8% (valid)\n",
      "Epoch 36 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.1993 (train)\t|\tAcc 92.0% (train)\n",
      "\tLoss 0.2678 (valid)\t|\tAcc 91.4% (valid)\n",
      "Epoch 37 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.2018 (train)\t|\tAcc 92.0% (train)\n",
      "\tLoss 0.2826 (valid)\t|\tAcc 91.2% (valid)\n",
      "Epoch 38 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.1983 (train)\t|\tAcc 92.0% (train)\n",
      "\tLoss 0.2774 (valid)\t|\tAcc 91.4% (valid)\n",
      "Epoch 39 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.1996 (train)\t|\tAcc 91.9% (train)\n",
      "\tLoss 0.2787 (valid)\t|\tAcc 90.8% (valid)\n",
      "Epoch 40 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.1975 (train)\t|\tAcc 92.3% (train)\n",
      "\tLoss 0.2692 (valid)\t|\tAcc 91.1% (valid)\n",
      "Epoch 41 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.1938 (train)\t|\tAcc 92.3% (train)\n",
      "\tLoss 0.2811 (valid)\t|\tAcc 91.0% (valid)\n",
      "Epoch 42 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.1940 (train)\t|\tAcc 92.3% (train)\n",
      "\tLoss 0.2797 (valid)\t|\tAcc 91.2% (valid)\n",
      "Epoch 43 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.1969 (train)\t|\tAcc 92.1% (train)\n",
      "\tLoss 0.2799 (valid)\t|\tAcc 91.2% (valid)\n",
      "Epoch 44 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.1925 (train)\t|\tAcc 92.3% (train)\n",
      "\tLoss 0.2793 (valid)\t|\tAcc 91.1% (valid)\n",
      "Epoch 45 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.1957 (train)\t|\tAcc 92.2% (train)\n",
      "\tLoss 0.2718 (valid)\t|\tAcc 91.0% (valid)\n",
      "Epoch 46 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.1988 (train)\t|\tAcc 92.2% (train)\n",
      "\tLoss 0.2704 (valid)\t|\tAcc 91.1% (valid)\n",
      "Epoch 47 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.1932 (train)\t|\tAcc 92.2% (train)\n",
      "\tLoss 0.2791 (valid)\t|\tAcc 91.1% (valid)\n",
      "Epoch 48 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.1929 (train)\t|\tAcc 92.3% (train)\n",
      "\tLoss 0.2821 (valid)\t|\tAcc 91.0% (valid)\n",
      "Epoch 49 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.1980 (train)\t|\tAcc 92.1% (train)\n",
      "\tLoss 0.2813 (valid)\t|\tAcc 91.0% (valid)\n",
      "Epoch 50 | time in 0 minutes, 16 seconds\n",
      "\tLoss 0.1963 (train)\t|\tAcc 92.4% (train)\n",
      "\tLoss 0.2828 (valid)\t|\tAcc 91.0% (valid)\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 50\n",
    "CLIP = 1.\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "\n",
    "  start_time = time.time()\n",
    "  train_loss, train_acc = train(model, train_dataloader, optimizer, criterion, CLIP)\n",
    "  valid_loss, valid_acc = evaluate(model, valid_dataloader, criterion)\n",
    "  end_time = time.time()\n",
    "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "  scheduler.step()\n",
    "\n",
    "  print(f'Epoch {epoch} | time in {epoch_mins} minutes, {epoch_secs} seconds')\n",
    "  print(f'\\tLoss {train_loss:.4f} (train)\\t|\\tAcc {train_acc * 100:.1f}% (train)')\n",
    "  print(f'\\tLoss {valid_loss:.4f} (valid)\\t|\\tAcc {valid_acc * 100:.1f}% (valid)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzR61Ch2NTU7"
   },
   "source": [
    "## テストデータで評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "id": "I8ju77-HEhVW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss 0.2765 (test)\t|\tAcc 90.3% (test)\n"
     ]
    }
   ],
   "source": [
    "loss, acc = evaluate(model, test_dataloader, criterion)\n",
    "print(f'\\tLoss {loss:.4f} (test)\\t|\\tAcc {acc * 100:.1f}% (test)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMY9y9YT6u6bdSCDqYHYnHj",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1HaIOpOtFSc4pjrdAglJT6cjgfkrJQIQ4",
   "name": "08_document_classification_with_RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
