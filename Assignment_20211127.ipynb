{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_20211127.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1-Fb_J7TgGA-B_giWLauA0gJvDhK3wp1x",
      "authorship_tag": "ABX9TyORuj2abyYX20Hg4dQjaqLJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomonari-masada/course2021-nlp/blob/main/Assignment_20211127.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mf-jw4S8rhTB"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjF1vzSosL5l"
      },
      "source": [
        "PATH = '/content/drive/MyDrive/2021Courses/NLP/'\n",
        "\n",
        "texts = dict()\n",
        "labels = dict()\n",
        "for tag in ['train', 'test']:\n",
        "  with open(f'{PATH}{tag}.npy', 'rb') as f:\n",
        "    texts[tag] = np.load(f)\n",
        "  with open(f'{PATH}{tag}_labels.npy', 'rb') as f:\n",
        "    labels[tag] = np.load(f)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuEe746MtFtr"
      },
      "source": [
        "for tag in ['train', 'test']:\n",
        "  texts[tag], labels[tag] = torch.tensor(texts[tag]), torch.tensor(labels[tag])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1osG09aHppg1"
      },
      "source": [
        "from torch.utils.data import Dataset, random_split\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, X, y):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.X.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.X[index], self.y[index]\n",
        "\n",
        "train_valid = MyDataset(texts['train'], labels['train'])\n",
        "test = MyDataset(texts['test'], labels['test'])\n",
        "\n",
        "valid_size = len(train_valid) // 5\n",
        "train_size = len(train_valid) - valid_size\n",
        "train, valid = random_split(train_valid,\n",
        "                            [train_size, valid_size],\n",
        "                            generator=torch.Generator().manual_seed(42)\n",
        "                            )"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfloEv0Osj2n"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "train_loader = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
        "valid_loader = DataLoader(valid, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLkGnlqfvQpp"
      },
      "source": [
        "EMBED_DIM = texts['train'].size(1)\n",
        "NUM_CLASS = len(np.unique(labels['train']))\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDFVMgRqyl4Q"
      },
      "source": [
        "def eval(model, criterion, loader):\n",
        "  model.eval()\n",
        "  \n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  total_size = 0\n",
        "  for input, target in loader:\n",
        "    with torch.no_grad():\n",
        "      input, target = input.to(device), target.to(device)\n",
        "      output = model(input)\n",
        "      loss = criterion(output, target)\n",
        "      total_loss += loss.item() * len(target)\n",
        "      total_acc += (output.argmax(1) == target).float().sum().item()\n",
        "      total_size += len(target)\n",
        "\n",
        "  return total_loss / total_size, total_acc / total_size"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHvS00cVvaVU"
      },
      "source": [
        "def train(model, criterion, optimizer, train_loader, valid_loader, n_epochs=100, scheduler=None):\n",
        "  model.train()\n",
        "\n",
        "  # training loop\n",
        "  for epoch in range(n_epochs):\n",
        "\n",
        "    train_loss = 0.0\n",
        "    for input, target in train_loader:\n",
        "      output = model(input.to(device))\n",
        "      loss = criterion(output, target.to(device))\n",
        "      train_loss += loss.item() * len(target) # 表示用の集計\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "    if scheduler:\n",
        "      scheduler.step()\n",
        "\n",
        "    valid_loss, valid_acc = eval(model, criterion, valid_loader)\n",
        "\n",
        "    # logging\n",
        "    print(f'epoch {epoch + 1:6d} |',\n",
        "          f'train loss {train_loss / train_size:8.4f} |',\n",
        "          f'valid loss {valid_loss:8.4f} | valid acc {valid_acc:8.3f}')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkRnetIrs9DX"
      },
      "source": [
        "class TextSentiment(nn.Module):\n",
        "  def __init__(self, embed_dim, num_class, hidden_dim=500):\n",
        "    super(TextSentiment, self).__init__()\n",
        "    self.fc1 = nn.Linear(embed_dim, hidden_dim)\n",
        "    self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
        "    self.out = nn.Linear(hidden_dim, num_class)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.out(x)\n",
        "    return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB0NIxhlxka5"
      },
      "source": [
        "model = TextSentiment(EMBED_DIM, NUM_CLASS, 500).to(device)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[50], gamma=0.1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAXpaWNwxqWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8e32533-4474-4805-d1d8-9d989d6b1332"
      },
      "source": [
        "train(model, criterion, optimizer, train_loader, valid_loader, 100, scheduler=scheduler)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch      1 | train loss   0.6494 | valid loss   0.5119 | valid acc    0.763\n",
            "epoch      2 | train loss   0.4262 | valid loss   0.4141 | valid acc    0.815\n",
            "epoch      3 | train loss   0.3811 | valid loss   0.3865 | valid acc    0.834\n",
            "epoch      4 | train loss   0.3644 | valid loss   0.3711 | valid acc    0.842\n",
            "epoch      5 | train loss   0.3560 | valid loss   0.3703 | valid acc    0.843\n",
            "epoch      6 | train loss   0.3523 | valid loss   0.3616 | valid acc    0.847\n",
            "epoch      7 | train loss   0.3457 | valid loss   0.3627 | valid acc    0.848\n",
            "epoch      8 | train loss   0.3421 | valid loss   0.3575 | valid acc    0.850\n",
            "epoch      9 | train loss   0.3408 | valid loss   0.3643 | valid acc    0.843\n",
            "epoch     10 | train loss   0.3396 | valid loss   0.3606 | valid acc    0.843\n",
            "epoch     11 | train loss   0.3362 | valid loss   0.3536 | valid acc    0.851\n",
            "epoch     12 | train loss   0.3342 | valid loss   0.3679 | valid acc    0.837\n",
            "epoch     13 | train loss   0.3332 | valid loss   0.3512 | valid acc    0.852\n",
            "epoch     14 | train loss   0.3307 | valid loss   0.3523 | valid acc    0.854\n",
            "epoch     15 | train loss   0.3289 | valid loss   0.3984 | valid acc    0.819\n",
            "epoch     16 | train loss   0.3300 | valid loss   0.3513 | valid acc    0.851\n",
            "epoch     17 | train loss   0.3276 | valid loss   0.3508 | valid acc    0.852\n",
            "epoch     18 | train loss   0.3256 | valid loss   0.3471 | valid acc    0.854\n",
            "epoch     19 | train loss   0.3249 | valid loss   0.3474 | valid acc    0.853\n",
            "epoch     20 | train loss   0.3245 | valid loss   0.3484 | valid acc    0.855\n",
            "epoch     21 | train loss   0.3270 | valid loss   0.3511 | valid acc    0.851\n",
            "epoch     22 | train loss   0.3229 | valid loss   0.3546 | valid acc    0.849\n",
            "epoch     23 | train loss   0.3211 | valid loss   0.3447 | valid acc    0.855\n",
            "epoch     24 | train loss   0.3200 | valid loss   0.3445 | valid acc    0.855\n",
            "epoch     25 | train loss   0.3198 | valid loss   0.3437 | valid acc    0.856\n",
            "epoch     26 | train loss   0.3196 | valid loss   0.3425 | valid acc    0.855\n",
            "epoch     27 | train loss   0.3194 | valid loss   0.3432 | valid acc    0.855\n",
            "epoch     28 | train loss   0.3183 | valid loss   0.3425 | valid acc    0.855\n",
            "epoch     29 | train loss   0.3167 | valid loss   0.3420 | valid acc    0.855\n",
            "epoch     30 | train loss   0.3124 | valid loss   0.3428 | valid acc    0.856\n",
            "epoch     31 | train loss   0.3124 | valid loss   0.3425 | valid acc    0.855\n",
            "epoch     32 | train loss   0.3106 | valid loss   0.3591 | valid acc    0.843\n",
            "epoch     33 | train loss   0.3121 | valid loss   0.3424 | valid acc    0.852\n",
            "epoch     34 | train loss   0.3121 | valid loss   0.3456 | valid acc    0.850\n",
            "epoch     35 | train loss   0.3072 | valid loss   0.3418 | valid acc    0.857\n",
            "epoch     36 | train loss   0.3067 | valid loss   0.3465 | valid acc    0.857\n",
            "epoch     37 | train loss   0.3029 | valid loss   0.3425 | valid acc    0.855\n",
            "epoch     38 | train loss   0.3063 | valid loss   0.3452 | valid acc    0.856\n",
            "epoch     39 | train loss   0.3024 | valid loss   0.3553 | valid acc    0.846\n",
            "epoch     40 | train loss   0.3026 | valid loss   0.3492 | valid acc    0.851\n",
            "epoch     41 | train loss   0.3005 | valid loss   0.3410 | valid acc    0.855\n",
            "epoch     42 | train loss   0.2977 | valid loss   0.3446 | valid acc    0.854\n",
            "epoch     43 | train loss   0.2963 | valid loss   0.3456 | valid acc    0.852\n",
            "epoch     44 | train loss   0.2937 | valid loss   0.3433 | valid acc    0.853\n",
            "epoch     45 | train loss   0.2929 | valid loss   0.3576 | valid acc    0.844\n",
            "epoch     46 | train loss   0.2923 | valid loss   0.3515 | valid acc    0.849\n",
            "epoch     47 | train loss   0.2921 | valid loss   0.3530 | valid acc    0.849\n",
            "epoch     48 | train loss   0.2880 | valid loss   0.3445 | valid acc    0.854\n",
            "epoch     49 | train loss   0.2867 | valid loss   0.3458 | valid acc    0.853\n",
            "epoch     50 | train loss   0.2847 | valid loss   0.3644 | valid acc    0.840\n",
            "epoch     51 | train loss   0.2775 | valid loss   0.3426 | valid acc    0.858\n",
            "epoch     52 | train loss   0.2759 | valid loss   0.3446 | valid acc    0.856\n",
            "epoch     53 | train loss   0.2754 | valid loss   0.3443 | valid acc    0.856\n",
            "epoch     54 | train loss   0.2750 | valid loss   0.3462 | valid acc    0.853\n",
            "epoch     55 | train loss   0.2750 | valid loss   0.3436 | valid acc    0.859\n",
            "epoch     56 | train loss   0.2744 | valid loss   0.3440 | valid acc    0.859\n",
            "epoch     57 | train loss   0.2745 | valid loss   0.3445 | valid acc    0.858\n",
            "epoch     58 | train loss   0.2740 | valid loss   0.3453 | valid acc    0.857\n",
            "epoch     59 | train loss   0.2745 | valid loss   0.3446 | valid acc    0.859\n",
            "epoch     60 | train loss   0.2735 | valid loss   0.3470 | valid acc    0.854\n",
            "epoch     61 | train loss   0.2734 | valid loss   0.3460 | valid acc    0.856\n",
            "epoch     62 | train loss   0.2729 | valid loss   0.3466 | valid acc    0.855\n",
            "epoch     63 | train loss   0.2725 | valid loss   0.3453 | valid acc    0.857\n",
            "epoch     64 | train loss   0.2729 | valid loss   0.3449 | valid acc    0.859\n",
            "epoch     65 | train loss   0.2722 | valid loss   0.3454 | valid acc    0.858\n",
            "epoch     66 | train loss   0.2720 | valid loss   0.3453 | valid acc    0.859\n",
            "epoch     67 | train loss   0.2716 | valid loss   0.3458 | valid acc    0.858\n",
            "epoch     68 | train loss   0.2714 | valid loss   0.3459 | valid acc    0.858\n",
            "epoch     69 | train loss   0.2711 | valid loss   0.3459 | valid acc    0.857\n",
            "epoch     70 | train loss   0.2712 | valid loss   0.3465 | valid acc    0.857\n",
            "epoch     71 | train loss   0.2705 | valid loss   0.3464 | valid acc    0.857\n",
            "epoch     72 | train loss   0.2702 | valid loss   0.3463 | valid acc    0.858\n",
            "epoch     73 | train loss   0.2700 | valid loss   0.3466 | valid acc    0.859\n",
            "epoch     74 | train loss   0.2699 | valid loss   0.3469 | valid acc    0.857\n",
            "epoch     75 | train loss   0.2694 | valid loss   0.3472 | valid acc    0.857\n",
            "epoch     76 | train loss   0.2694 | valid loss   0.3476 | valid acc    0.856\n",
            "epoch     77 | train loss   0.2691 | valid loss   0.3470 | valid acc    0.858\n",
            "epoch     78 | train loss   0.2684 | valid loss   0.3510 | valid acc    0.853\n",
            "epoch     79 | train loss   0.2684 | valid loss   0.3485 | valid acc    0.855\n",
            "epoch     80 | train loss   0.2683 | valid loss   0.3502 | valid acc    0.852\n",
            "epoch     81 | train loss   0.2678 | valid loss   0.3473 | valid acc    0.858\n",
            "epoch     82 | train loss   0.2675 | valid loss   0.3477 | valid acc    0.857\n",
            "epoch     83 | train loss   0.2671 | valid loss   0.3481 | valid acc    0.856\n",
            "epoch     84 | train loss   0.2675 | valid loss   0.3512 | valid acc    0.852\n",
            "epoch     85 | train loss   0.2666 | valid loss   0.3482 | valid acc    0.856\n",
            "epoch     86 | train loss   0.2661 | valid loss   0.3487 | valid acc    0.856\n",
            "epoch     87 | train loss   0.2662 | valid loss   0.3483 | valid acc    0.856\n",
            "epoch     88 | train loss   0.2658 | valid loss   0.3483 | valid acc    0.856\n",
            "epoch     89 | train loss   0.2654 | valid loss   0.3483 | valid acc    0.856\n",
            "epoch     90 | train loss   0.2656 | valid loss   0.3489 | valid acc    0.857\n",
            "epoch     91 | train loss   0.2647 | valid loss   0.3490 | valid acc    0.856\n",
            "epoch     92 | train loss   0.2650 | valid loss   0.3500 | valid acc    0.855\n",
            "epoch     93 | train loss   0.2644 | valid loss   0.3487 | valid acc    0.856\n",
            "epoch     94 | train loss   0.2644 | valid loss   0.3492 | valid acc    0.856\n",
            "epoch     95 | train loss   0.2648 | valid loss   0.3507 | valid acc    0.855\n",
            "epoch     96 | train loss   0.2638 | valid loss   0.3493 | valid acc    0.857\n",
            "epoch     97 | train loss   0.2634 | valid loss   0.3569 | valid acc    0.850\n",
            "epoch     98 | train loss   0.2633 | valid loss   0.3495 | valid acc    0.856\n",
            "epoch     99 | train loss   0.2632 | valid loss   0.3500 | valid acc    0.856\n",
            "epoch    100 | train loss   0.2626 | valid loss   0.3497 | valid acc    0.857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gLwC3XDdK3-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "100ecafe-71a5-4f32-ffbf-1f266f9f462b"
      },
      "source": [
        "loss, acc = eval(model, criterion, test_loader)\n",
        "print(f'test loss {loss:8.4f} | test acc {acc:8.3f}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss   0.3410 | test acc    0.856\n"
          ]
        }
      ]
    }
  ]
}